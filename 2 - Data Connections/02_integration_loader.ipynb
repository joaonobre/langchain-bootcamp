{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "#  Integrations\n",
    "\n",
    "Integrations are document loaders that are integrated with 3rd party services like Google Cloud or websites like Wikipedia.\n",
    "\n",
    "More on integrations here: https://python.langchain.com/docs/modules/data_connection/document_loaders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244f42d8-2349-446e-a1c2-ae4b8d3ee38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f664be-dcd8-4b29-afb8-0fb72451509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacker News loader\n",
    "loader = HNLoader('https://news.ycombinator.com/item?id=30084169')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364d3c74-a88c-49b9-b102-1a206203c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb1aa8f-97d7-48be-8ca3-ddb9df553ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nicholast on Jan 26, 2022  \n",
      "             | next [–] \n",
      "\n",
      "He was also a jazz musician (the clarinet), a somewhat accomplished juggler, a devoted unicycle enthusiast, and left behind a basement full of contraptions he was building in various states of finish - like the electronic mouse navigating a maze, a chess playing machine, and all other kinds of curiosities. His papers are coherent and still relevant to this day and follow the birth of each of these fields like information theory and artificial intelligence. Who knows what else he might have been working on at Bell labs that we may not be privy too.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049a4a99-5124-4f69-a4fc-185a6741a88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://news.ycombinator.com/item?id=30084169',\n",
       " 'title': 'How Claude Shannon helped kick-start machine learning'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570fdcc8-5052-4860-9b96-f962a17ffee1",
   "metadata": {},
   "source": [
    "## Create Summary of First Comment\n",
    "\n",
    "We can now combine LLMs with loaders. The following example shows how to summarize an user comment on an Hacker News post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cca327-1a29-49a9-b6bb-bb8caa18ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b4db08-9808-4f50-8401-35d3968935b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(key=\"OPENAI_API_KEY\")\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dbf3a0-1ec2-4142-977b-829891171bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = HumanMessagePromptTemplate.from_template('Please give me a single sentence summary of the following text:\\n{document}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ed4f58-bc83-451f-9ab1-367f52dd3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bdcccc-8ab3-4714-a619-c5c38b43ee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person mentioned in the text was a multi-talented individual who had a passion for music, juggling, unicycling, and building various contraptions, with coherent and relevant papers related to information theory and artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "result = model(chat_prompt.format_prompt(document=data[0].page_content).to_messages())\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b231091",
   "metadata": {},
   "source": [
    "Let's now use the Wikipedia integration to answer some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae41ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "\n",
    "def answer_question(person_name,question):\n",
    "\n",
    "    loader = WikipediaLoader(query=person_name, load_max_docs=2)\n",
    "    data = loader.load()\n",
    "\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template('Based on the following text {context} answer the following question: {question}')\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "    result = model(chat_prompt.format_prompt(context=data, question = question).to_messages())\n",
    "    \n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d4a5286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cristiano Ronaldo was born on February 5, 1985.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Cristiano Ronaldo\", \"When was he born?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2cb2b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cristiano Ronaldo has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship, and the UEFA Nations League.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Cristiano Ronaldo\", \"How many championships has he won?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03bc0faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yann LeCun's first academic contribution was the proposal of an early form of the back-propagation learning algorithm for neural networks during his Ph.D. in Computer Science from Université Pierre et Marie Curie in 1987.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Yann LeCun\", \"What was his first academic contribution?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
